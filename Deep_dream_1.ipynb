{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Deep_dream_1.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN6XqAAeQmZBLsPAQzYaP/H",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kotsun32/Google_deep_dream_PyTorch/blob/main/Deep_dream_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ryVUMH-lFnwZ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import enum\n",
        "from collections import namedtuple\n",
        "import argparse\n",
        "import numbers\n",
        "import math\n",
        "\n",
        "\n",
        "# Deep learning related imports\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import models\n",
        "from torchvision import transforms\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "import cv2 as cv\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt  # visualizations"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The 2 datasets we'll be leveraging\n",
        "class SupportedPretrainedWeights(enum.Enum):\n",
        "    IMAGENET = 0\n",
        "    PLACES_365 = 1\n",
        "    \n",
        "\n",
        "# The 2 models we'll be using\n",
        "class SupportedModels(enum.Enum):\n",
        "    VGG16_EXPERIMENTAL = 0,\n",
        "    RESNET50 = 1\n",
        "    \n",
        "\n",
        "# Commonly used paths, let's define them here as constants\n",
        "DATA_DIR_PATH = os.path.join(os.getcwd(), 'data')\n",
        "INPUT_DATA_PATH = os.path.join(DATA_DIR_PATH, 'input')\n",
        "BINARIES_PATH = os.path.join(os.getcwd(), 'models', 'binaries')\n",
        "OUT_IMAGES_PATH = os.path.join(DATA_DIR_PATH, 'out-images')\n",
        "\n",
        "# Make sure these exist as the rest of the code relies on it\n",
        "os.makedirs(BINARIES_PATH, exist_ok=True)\n",
        "os.makedirs(OUT_IMAGES_PATH, exist_ok=True)\n",
        "\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # checking whether you have a GPU\n",
        "\n",
        "# Images will be normalized using these, because the CNNs were trained with normalized images as well!\n",
        "IMAGENET_MEAN_1 = np.array([0.485, 0.456, 0.406], dtype=np.float32)\n",
        "IMAGENET_STD_1 = np.array([0.229, 0.224, 0.225], dtype=np.float32)"
      ],
      "metadata": {
        "id": "Lfc6rPCwFvp2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Vgg16Experimental(torch.nn.Module):\n",
        "    \n",
        "    def __init__(self, pretrained_weights, requires_grad=False, show_progress=False):\n",
        "        super().__init__()\n",
        "\n",
        "        # Only ImageNet weights are supported for now for this model\n",
        "        if pretrained_weights == SupportedPretrainedWeights.IMAGENET.name:\n",
        "            vgg16 = models.vgg16(pretrained=True, progress=show_progress).eval()\n",
        "        else:\n",
        "            raise Exception(f'Pretrained weights {pretrained_weights} not yet supported for {self.__class__.__name__} model.')\n",
        "\n",
        "        # I just used the official PyTorch implementation to figure out how to dissect VGG16:\n",
        "        # https://github.com/pytorch/vision/blob/master/torchvision/models/vgg.py\n",
        "        vgg_pretrained_features = vgg16.features\n",
        "\n",
        "        # I've exposed the best/most interesting layers in my subjective opinion (mp5 is not that good though)\n",
        "        self.layer_names = ['relu3_3', 'relu4_1', 'relu4_2', 'relu4_3', 'relu5_1', 'relu5_2', 'relu5_3', 'mp5']\n",
        "\n",
        "        # 31 layers in total for the VGG16\n",
        "        self.conv1_1 = vgg_pretrained_features[0]\n",
        "        self.relu1_1 = vgg_pretrained_features[1]\n",
        "        self.conv1_2 = vgg_pretrained_features[2]\n",
        "        self.relu1_2 = vgg_pretrained_features[3]\n",
        "        self.max_pooling1 = vgg_pretrained_features[4]\n",
        "        self.conv2_1 = vgg_pretrained_features[5]\n",
        "        self.relu2_1 = vgg_pretrained_features[6]\n",
        "        self.conv2_2 = vgg_pretrained_features[7]\n",
        "        self.relu2_2 = vgg_pretrained_features[8]\n",
        "        self.max_pooling2 = vgg_pretrained_features[9]\n",
        "        self.conv3_1 = vgg_pretrained_features[10]\n",
        "        self.relu3_1 = vgg_pretrained_features[11]\n",
        "        self.conv3_2 = vgg_pretrained_features[12]\n",
        "        self.relu3_2 = vgg_pretrained_features[13]\n",
        "        self.conv3_3 = vgg_pretrained_features[14]\n",
        "        self.relu3_3 = vgg_pretrained_features[15]\n",
        "        self.max_pooling3 = vgg_pretrained_features[16]\n",
        "        self.conv4_1 = vgg_pretrained_features[17]\n",
        "        self.relu4_1 = vgg_pretrained_features[18]\n",
        "        self.conv4_2 = vgg_pretrained_features[19]\n",
        "        self.relu4_2 = vgg_pretrained_features[20]\n",
        "        self.conv4_3 = vgg_pretrained_features[21]\n",
        "        self.relu4_3 = vgg_pretrained_features[22]\n",
        "        self.max_pooling4 = vgg_pretrained_features[23]\n",
        "        self.conv5_1 = vgg_pretrained_features[24]\n",
        "        self.relu5_1 = vgg_pretrained_features[25]\n",
        "        self.conv5_2 = vgg_pretrained_features[26]\n",
        "        self.relu5_2 = vgg_pretrained_features[27]\n",
        "        self.conv5_3 = vgg_pretrained_features[28]\n",
        "        self.relu5_3 = vgg_pretrained_features[29]\n",
        "        self.max_pooling5 = vgg_pretrained_features[30]\n",
        "\n",
        "        # Turn off these because we'll be using a pretrained network\n",
        "        # if we didn't do this PyTorch would be saving gradients and eating up precious memory!\n",
        "        if not requires_grad:\n",
        "            for param in self.parameters():\n",
        "                param.requires_grad = False\n",
        "\n",
        "    # Just expose every single layer during the forward pass\n",
        "    def forward(self, x):\n",
        "        x = self.conv1_1(x)\n",
        "        conv1_1 = x\n",
        "        x = self.relu1_1(x)\n",
        "        relu1_1 = x\n",
        "        x = self.conv1_2(x)\n",
        "        conv1_2 = x\n",
        "        x = self.relu1_2(x)\n",
        "        relu1_2 = x\n",
        "        x = self.max_pooling1(x)\n",
        "        x = self.conv2_1(x)\n",
        "        conv2_1 = x\n",
        "        x = self.relu2_1(x)\n",
        "        relu2_1 = x\n",
        "        x = self.conv2_2(x)\n",
        "        conv2_2 = x\n",
        "        x = self.relu2_2(x)\n",
        "        relu2_2 = x\n",
        "        x = self.max_pooling2(x)\n",
        "        x = self.conv3_1(x)\n",
        "        conv3_1 = x\n",
        "        x = self.relu3_1(x)\n",
        "        relu3_1 = x\n",
        "        x = self.conv3_2(x)\n",
        "        conv3_2 = x\n",
        "        x = self.relu3_2(x)\n",
        "        relu3_2 = x\n",
        "        x = self.conv3_3(x)\n",
        "        conv3_3 = x\n",
        "        x = self.relu3_3(x)\n",
        "        relu3_3 = x\n",
        "        x = self.max_pooling3(x)\n",
        "        x = self.conv4_1(x)\n",
        "        conv4_1 = x\n",
        "        x = self.relu4_1(x)\n",
        "        relu4_1 = x\n",
        "        x = self.conv4_2(x)\n",
        "        conv4_2 = x\n",
        "        x = self.relu4_2(x)\n",
        "        relu4_2 = x\n",
        "        x = self.conv4_3(x)\n",
        "        conv4_3 = x\n",
        "        x = self.relu4_3(x)\n",
        "        relu4_3 = x\n",
        "        x = self.max_pooling4(x)\n",
        "        x = self.conv5_1(x)\n",
        "        conv5_1 = x\n",
        "        x = self.relu5_1(x)\n",
        "        relu5_1 = x\n",
        "        x = self.conv5_2(x)\n",
        "        conv5_2 = x\n",
        "        x = self.relu5_2(x)\n",
        "        relu5_2 = x\n",
        "        x = self.conv5_3(x)\n",
        "        conv5_3 = x\n",
        "        x = self.relu5_3(x)\n",
        "        relu5_3 = x\n",
        "        mp5 = self.max_pooling5(x)\n",
        "\n",
        "        # Finally, expose only the layers that you want to experiment with here\n",
        "        vgg_outputs = namedtuple(\"VggOutputs\", self.layer_names)\n",
        "        out = vgg_outputs(relu3_3, relu4_1, relu4_2, relu4_3, relu5_1, relu5_2, relu5_3, mp5)\n",
        "\n",
        "        return out\n",
        "    \n",
        "    \n",
        "def fetch_and_prepare_model(model_type, pretrained_weights):\n",
        "    if model_type == SupportedModels.VGG16_EXPERIMENTAL.name:\n",
        "        model = Vgg16Experimental(pretrained_weights, requires_grad=False, show_progress=True).to(DEVICE)\n",
        "    elif model_type == SupportedModels.RESNET50.name:\n",
        "        # We'll define the ResNet50 later\n",
        "        model = ResNet50(pretrained_weights, requires_grad=False, show_progress=True).to(DEVICE)\n",
        "    else:\n",
        "        raise Exception('Model not yet supported.')\n",
        "    return model"
      ],
      "metadata": {
        "id": "-qp90HkHGR88"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SWeLtC6uHgMY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}